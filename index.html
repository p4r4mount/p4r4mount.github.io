<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Song's blog - RISE FROM THE ASHES</title><meta name="author" content="p4r4mount"><meta name="copyright" content="p4r4mount"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Event Camera Fresher">
<meta property="og:type" content="website">
<meta property="og:title" content="Song&#39;s blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Song&#39;s blog">
<meta property="og:description" content="Event Camera Fresher">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s2.loli.net/2022/11/02/eQmbE4RwJ78Wr2A.png">
<meta property="article:author" content="p4r4mount">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2022/11/02/eQmbE4RwJ78Wr2A.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Song\'s blog',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-09-03 15:50:07'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="Song's blog" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2022/11/02/eQmbE4RwJ78Wr2A.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/github-event.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Song's blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Song's blog</h1><div id="site-subtitle"><span id="subtitle"></span></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2023/07/14/utils/" title="Masked and Adaptive Transformer for Exemplar Based Image Translation"><img class="post_bg" src="/2023/07/14/utils/image-20230820224628323.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Masked and Adaptive Transformer for Exemplar Based Image Translation"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/07/14/utils/" title="Masked and Adaptive Transformer for Exemplar Based Image Translation">Masked and Adaptive Transformer for Exemplar Based Image Translation</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-07-14T07:08:38.000Z" title="Created 2023-07-14 15:08:38">2023-07-14</time></span></div><div class="content">开 缝
Low-Light Image Enhancement via Structure Modeling and Guidance
paper，code
​	用结构信息做低光照图像增强的方法，整个网络如下图所示，结构信息是低光照图像估计出来的，需要学习的只有融合结构信息和图像的c部分，Structure-Guided Enhancement。

​	主要位于decoder部分，IsI_sIs​为原始图像预测得到的结构信息，可用其增强appearance预测，这种增强可以用两个方面解释，首先，结构信息可以增强图像细节，尤其是对于低信噪比的黑暗区域，其次是边缘信息有助于区分不同的暗区，并建立更好的关系。
​	假设SGEM的decoder有K层，每层的输入为dj∈Rb×p×q,j∈[1,K]d_j\in R^{b\times p\times q},j\in[1,K]dj​∈Rb×p×q,j∈[1,K]，bpq分别表示通道数，高，宽。在第j层，我们首先将结构映射IsI_sIs​调整为与djd_jdj​同样的大小，得到IsjI_s^jIsj​，为了利用结构映射的指导，我们提出从IsjI_s^ ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/07/06/shuangmu/" title="Learning Event Guided High Dynamic Range Video Reconstruction"><img class="post_bg" src="/2023/07/06/shuangmu/image-20230706164138866.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Learning Event Guided High Dynamic Range Video Reconstruction"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/07/06/shuangmu/" title="Learning Event Guided High Dynamic Range Video Reconstruction">Learning Event Guided High Dynamic Range Video Reconstruction</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-07-06T08:23:49.000Z" title="Created 2023-07-06 16:23:49">2023-07-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">Learning Event Guided High Dynamic Range Video Reconstruction
paper, code
Abstract
​	当使用传统相机捕捉运动场景时，由于帧率和曝光时间无法权衡，基于帧的HDR视频重建效果不够好，事件相机有大动态范围和高时间分辨率，没有上述问题，这是一个LDR到HDR的思路。本文中，我们提出了一个用于事件引导HDR视频重建的多模态学习框架。为了更好地利用两种模态对同一场景的知识，我们提出了一种多模态表示对齐策略（ multimodal representation alignment strategy）来学习共享潜在空间（shared latent space），和一种融合模块（fusion module）来针对不同区域不同动态范围的两种类型信号进行互补。在重构的HDR视频中反复利用时间相关性来抑制闪烁（lickering effects）。提出的HDRev-Net在合成数据和实际数据方面都sota。
Method
3.1. Formulation：
​	Event generation and stacking. 用v ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2023/06/06/HyperE2vid/" title="HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks"><img class="post_bg" src="/2023/06/06/HyperE2vid/image-20230606161530019.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/06/06/HyperE2vid/" title="HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks">HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-06-06T08:02:37.000Z" title="Created 2023-06-06 16:02:37">2023-06-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">HyperE2VID: Improving Event-Based Video Reconstruction via Hypernetworks
code,  paper
Abstract
​	没啥motivation，提出了HyperE2VID，使用hypernetworks和动态卷积（dynamic convolutions）来生成每像素的自适应filters，该滤波器由context fusion模块指导，该模块结合voxel grid和上一帧重建的信息，类似spade。还使用了课程学习策略（curriculum learning strategy）来使训练更robust。比ET-Net参数更少，性能更好。

Method
​	事件处理跟正常方法差别不大，但是进行了一点约束，使每个生成的图像只依赖于过去的事件。这样方法可以用于从相机中实时重构事件。用固定时间ΔT\Delta TΔT的voxel grid来表征事件，B=5。
HyperE2VID：
​	inference阶段，每个时间间隔重构一帧图像，主干网络类似E2VID，然后，用hypernetworks, dynamic c ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/05/16/evreal/" title="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction"><img class="post_bg" src="/2023/05/16/evreal/image-20230516201910502.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/05/16/evreal/" title="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction">EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-05-16T12:08:28.000Z" title="Created 2023-05-16 20:08:28">2023-05-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">EVREAL: Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction
CVPRW 2023  [paper](2305.00434.pdf (arxiv.org)), [code](ercanburak/EVREAL: EVREAL: Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction (CVPRW 2023) (github.com))
Abstract:
​	事件流对human来说不太好理解，因此需要intensity重构，最近的一些深度学习工作体现出了重构的意义，但这个问题并没有被完全解决。为了更好的对比不同方法，标准化evaluation protocols与不同的测试集是有必要的。我们提出了一种统一的评估方法，并介绍了一个名为EVREAL的开源框架，对提出的各种基于事件的视频重建方法进行了全面的benchmark测试与分析。基 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2023/04/24/vrt/" title="VRT:A Video Restoration Transformer"><img class="post_bg" src="/2023/04/24/vrt/image-20230424062932595.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="VRT:A Video Restoration Transformer"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/04/24/vrt/" title="VRT:A Video Restoration Transformer">VRT:A Video Restoration Transformer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-04-23T22:23:44.000Z" title="Created 2023-04-24 06:23:44">2023-04-24</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">VRT: A Video Restoration Transformer
paper,  code
Abstract
​	视频恢复(如视频超分辨率)旨在从低质量帧恢复高质量帧。与单个图像恢复不同，视频恢复通常需要利用多个相邻但通常不对齐的视频帧的时间信息，现有的深度方法通常通过利用滑动窗口策略或循环结构来解决这个问题，这些方法要么受到逐帧恢复的限制，要么缺乏远程建模能力。
​	我们提出一个具有平行帧预测和长时间依赖建模能力的Video Restoration Transformer。具体来说，VRT由多个尺度组成，每个尺度由两种模块组成:时间相互自注意（ temporal mutual self attention，TMSA）和平行扭曲（parallel warping）。TMSA将视频分割成小片段，利用mutual attention进行joint运动估计、特征对齐和特征融合，利用自注意力进行特征提取。为了实现cross-clip interactions，视频序列每隔一层就会被移动。此外，利用parallel warping进一步融合相邻帧的信息。实验good。
Video Res ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/04/13/local-global-SR/" title="Local-Global Temporal Difference Learning for Satellite Video Super-Resolution"><img class="post_bg" src="/2023/04/13/local-global-SR/image-20230413070915148.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Local-Global Temporal Difference Learning for Satellite Video Super-Resolution"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/04/13/local-global-SR/" title="Local-Global Temporal Difference Learning for Satellite Video Super-Resolution">Local-Global Temporal Difference Learning for Satellite Video Super-Resolution</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-04-12T23:00:53.000Z" title="Created 2023-04-13 07:00:53">2023-04-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">Local-Global Temporal Difference Learning for Satellite Video Super-Resolution
paper, code
暂时在TCSVT发表
Abstract：
​	基于光流（optical-flow-based）和基于核（kernel-based）的时间补偿（temporal compensation）方法在卫星视频超分辨率（VSR）中得到了广泛的研究。但这些技术计算量超大，在复杂运动条件下容易失效。
​	在本文中，我们提出利用定义良好的temporal difference进行efficient和robust的temporal compensation。为了充分利用框架内的时间信息，我们分别建模了短期和长期的temporal  difference，因为它们提供了独特的互补特性。specifically，short-term temporal difference module（S-TDM）用于从相邻帧间的residual map提取local motion representation，这能够为精确的纹理表示提供更多的 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2023/03/17/frame-difference-based-temporal-loss/" title="Blind Video Temporal Consistency via Deep Video Prior"><img class="post_bg" src="/2023/03/17/frame-difference-based-temporal-loss/image-20230320210652223.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Blind Video Temporal Consistency via Deep Video Prior"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/03/17/frame-difference-based-temporal-loss/" title="Blind Video Temporal Consistency via Deep Video Prior">Blind Video Temporal Consistency via Deep Video Prior</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-03-17T03:11:26.000Z" title="Created 2023-03-17 11:11:26">2023-03-17</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">Blind Video Temporal Consistency via Deep Video Prior
Abstract：
​	新的通用blind temporal consistency方法，该方法直接在一对原始的和处理过的视频上训练，不用再大型数据集上训练。与大多数基于光流的时间一致性方法不同，我们证明了时间一致性可以通过Deep Video  Prior再视频上训cnn实现。
​	此外，还提出了精心设计的iteratively reweighted 训练策略，以解决具有挑战性的多模态不一致性问题。7个视频任务上验证方法，goodgood。代码：[ChenyangLEI/deep-video-prior: NeurIPS 2020] Blind Video Temporal Consistency via Deep Video Prior (github.com)
Introduction
​	我们的框架没有任何手工的时间正则化来提高一致性，方法与DIP（Deep Image Prior）有关，其观察到生成器网络的结构足以捕获自然图像的低级统计特征。DIP以噪声为输入，训练网络 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/03/13/ReRe/" title="Consistent Video Style Transfer via Relaxation and Regularization"><img class="post_bg" src="/2023/03/13/ReRe/image-20230313202205533.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Consistent Video Style Transfer via Relaxation and Regularization"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/03/13/ReRe/" title="Consistent Video Style Transfer via Relaxation and Regularization">Consistent Video Style Transfer via Relaxation and Regularization</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-03-13T12:17:45.000Z" title="Created 2023-03-13 20:17:45">2023-03-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">Consistent Video Style Transfer via Relaxation and Regularization
2020 TIP
Abstract
​	temporally consistent style transfer是有挑战性的东西，现有的方法无论是依赖于大量具有光流的视频数据，还是使用单帧regularizers，都无法处理强烈的运动或复杂的变化，因此在真实视频上的性能有限。
​	在本文中，我们通过共同考虑stylization和temporal consistency的内在属性来解决这个问题。我们首先找出风格迁移与时间一致性冲突的原因，并提出通过relax（放松）目标函数来调和这一矛盾，从而使风格化损失项对运动更具鲁棒性。通过relaxation，风格迁移对帧间变化更robust。然后，我们提供了一个新的formulation和时间一致性的理解。在此基础上，我们分析了现有训练策略的不足，并推导出一种新的正则化方法。
​	实验表明，所提出的正则化方法可以更好地平衡空间和时间性能。基于松弛和正则化，我们设计了一个zero-shot视频风格传输框架。此外，为了 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2023/03/13/CCPL/" title="CCPL:Contrastive Coherence Preserving Loss for Versatile Style Transfer"><img class="post_bg" src="/2023/03/13/CCPL/image-20230321164058524.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CCPL:Contrastive Coherence Preserving Loss for Versatile Style Transfer"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/03/13/CCPL/" title="CCPL:Contrastive Coherence Preserving Loss for Versatile Style Transfer">CCPL:Contrastive Coherence Preserving Loss for Versatile Style Transfer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-03-13T06:49:59.000Z" title="Created 2023-03-13 14:49:59">2023-03-13</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">CCPL: Contrastive Coherence Preserving Loss for Versatile Style Transfer
ECCV Oral 2022
论文：CCPL: Contrastive Coherence Preserving Loss for Versatile Style Transfer
代码：github.com
Abstract:
​	在本文中，我们的目标是设计一种通用的风格转换方法，能够在训练过程中不需要看到视频的情况下，同时进行艺术风格、照片现实风格和视频风格的转换。以往的单帧方法通过对图像加上很强的约束来保持时间一致性，但这样做在很多情况下都会寄。
​	Instead，我们做了一个mild and reasonable的假设：global inconsistency is dominated by local inconsistencies，局部的不一致性决定整体不一致性，从而提出了一个genetic（通用的）Contrastive Coherence Preserving Loss（CCPL），应用于local patches。CCPL ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/03/09/video-to-video/" title="Video-to-Video Synthesis"><img class="post_bg" src="/2023/03/09/video-to-video/image-20230310164418612.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Video-to-Video Synthesis"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/03/09/video-to-video/" title="Video-to-Video Synthesis">Video-to-Video Synthesis</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-03-09T03:15:15.000Z" title="Created 2023-03-09 11:15:15">2023-03-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">Video-to-Video Synthesis       NIPS 2018
Abstract
​	我们研究视频到视频合成问题，其目标是学习从输入源视频(例如，语义分割掩码序列)到输出逼真视频的映射函数，该输出视频精确地描绘了源视频的内容。虽然图像到图像的翻译问题是一个流行的话题，但视频到视频合成问题在文献中很少被探索。在没有建模时间动态（temporal dynamics）的情况下，直接将现有的图像合成方法应用于输入视频往往会导致时间不连贯的低视觉质量的视频。
​	在本文中，我们提出了一种生成对抗学习框架下的视频到视频合成方法。通过精心设计的生成器和鉴别器，再加上时空对抗目标（spatio-temporal adversarial objective），我们在包括分割掩模（segmentation masks）、草图（sketches）和姿势（poses）在内的各种输入格式上实现了高分辨率、逼真性、时间一致性（temporally coherent）的视频结果。
​	在多个baseline上的实验表明，与强baseline相比，我们的方法具有优势。特别是，我们的模型能够合成长达3 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><a class="page-number" href="/page/3/#content-inner">3</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2022/11/02/eQmbE4RwJ78Wr2A.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">p4r4mount</div><div class="author-info__description">Event Camera Fresher</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/p4r4mount"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/07/14/utils/" title="Masked and Adaptive Transformer for Exemplar Based Image Translation"><img src="/2023/07/14/utils/image-20230820224628323.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Masked and Adaptive Transformer for Exemplar Based Image Translation"/></a><div class="content"><a class="title" href="/2023/07/14/utils/" title="Masked and Adaptive Transformer for Exemplar Based Image Translation">Masked and Adaptive Transformer for Exemplar Based Image Translation</a><time datetime="2023-07-14T07:08:38.000Z" title="Created 2023-07-14 15:08:38">2023-07-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/06/shuangmu/" title="Learning Event Guided High Dynamic Range Video Reconstruction"><img src="/2023/07/06/shuangmu/image-20230706164138866.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Learning Event Guided High Dynamic Range Video Reconstruction"/></a><div class="content"><a class="title" href="/2023/07/06/shuangmu/" title="Learning Event Guided High Dynamic Range Video Reconstruction">Learning Event Guided High Dynamic Range Video Reconstruction</a><time datetime="2023-07-06T08:23:49.000Z" title="Created 2023-07-06 16:23:49">2023-07-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/06/06/HyperE2vid/" title="HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks"><img src="/2023/06/06/HyperE2vid/image-20230606161530019.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks"/></a><div class="content"><a class="title" href="/2023/06/06/HyperE2vid/" title="HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks">HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks</a><time datetime="2023-06-06T08:02:37.000Z" title="Created 2023-06-06 16:02:37">2023-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/16/evreal/" title="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction"><img src="/2023/05/16/evreal/image-20230516201910502.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction"/></a><div class="content"><a class="title" href="/2023/05/16/evreal/" title="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction">EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction</a><time datetime="2023-05-16T12:08:28.000Z" title="Created 2023-05-16 20:08:28">2023-05-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/24/vrt/" title="VRT:A Video Restoration Transformer"><img src="/2023/04/24/vrt/image-20230424062932595.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="VRT:A Video Restoration Transformer"/></a><div class="content"><a class="title" href="/2023/04/24/vrt/" title="VRT:A Video Restoration Transformer">VRT:A Video Restoration Transformer</a><time datetime="2023-04-23T22:23:44.000Z" title="Created 2023-04-24 06:23:44">2023-04-24</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/paper/"><span class="card-category-list-name">paper</span><span class="card-category-list-count">16</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/tricks-%E6%80%BB%E7%BB%93/"><span class="card-category-list-name">tricks 总结</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9D%82%E6%9D%82%E6%8A%80%E6%9C%AF/"><span class="card-category-list-name">杂杂技术</span><span class="card-category-list-count">2</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/Event-camera/" style="font-size: 1.5em; color: #99a9bf">Event camera</a> <a href="/tags/Image-Generation/" style="font-size: 1.1em; color: #999">Image Generation</a> <a href="/tags/Video-Super-Resolution/" style="font-size: 1.1em; color: #999">Video Super-Resolution</a> <a href="/tags/code/" style="font-size: 1.1em; color: #999">code</a> <a href="/tags/markdown/" style="font-size: 1.1em; color: #999">markdown</a> <a href="/tags/style-transfer/" style="font-size: 1.1em; color: #999">style transfer</a> <a href="/tags/video-generation-inpainting/" style="font-size: 1.1em; color: #999">video generation/inpainting</a> <a href="/tags/video-restoration/" style="font-size: 1.1em; color: #999">video restoration</a> <a href="/tags/video-transfer/" style="font-size: 1.3em; color: #99a1ac">video transfer</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/07/"><span class="card-archive-list-date">July 2023</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/06/"><span class="card-archive-list-date">June 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/05/"><span class="card-archive-list-date">May 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/04/"><span class="card-archive-list-date">April 2023</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/03/"><span class="card-archive-list-date">March 2023</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/12/"><span class="card-archive-list-date">December 2022</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/11/"><span class="card-archive-list-date">November 2022</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/10/"><span class="card-archive-list-date">October 2022</span><span class="card-archive-list-count">3</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">21</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2023-09-03T07:50:07.466Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By p4r4mount</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    window.typed = new Typed("#subtitle", {
      strings: ["RISE FROM THE ASHES"],
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = 'RISE FROM THE ASHES'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>