<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Song's blog - RISE FROM THE ASHES</title><meta name="author" content="p4r4mount"><meta name="copyright" content="p4r4mount"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Event Camera Fresher">
<meta property="og:type" content="website">
<meta property="og:title" content="Song&#39;s blog">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Song&#39;s blog">
<meta property="og:description" content="Event Camera Fresher">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://s2.loli.net/2022/11/02/eQmbE4RwJ78Wr2A.png">
<meta property="article:author" content="p4r4mount">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2022/11/02/eQmbE4RwJ78Wr2A.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/page/2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Song\'s blog',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-09-03 15:50:07'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="Song's blog" type="application/atom+xml">
<link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2022/11/02/eQmbE4RwJ78Wr2A.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/github-event.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Song's blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Song's blog</h1><div id="site-subtitle"><span id="subtitle"></span></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2023/03/08/some-ideas/" title="some ideas"><img class="post_bg" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="some ideas"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/03/08/some-ideas/" title="some ideas">some ideas</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-03-08T15:29:13.000Z" title="Created 2023-03-08 23:29:13">2023-03-08</time></span></div><div class="content">主要思路: 在e2vid网络的基础上进行改进，从两个方面入手：1.从视频生成的角度出发，在网络中融入网络，增强网络的时序相关性（temporal coherence）2.从图像生成的角度出发，增强网络重构的空间约束，使每一帧重构图像质量更高（修改bn，类似adain，spade，sean）。
视频生成调研：
1.Video-to-Video Synthesis：Deep Video Inpainting (readpaper.com)
Video-to-Video Synthesis 高清视频生成 论文解读 - 知乎 (zhihu.com)
建模为马尔可夫过程求解
2.Deep Video Inpainting：图像修复的一篇工作，可以学习一下其中结合光流的方法，跟第一篇一起看
Deep Video Inpainting论文以及代码解析 - 知乎 (zhihu.com)
mcahny/Deep-Video-Inpainting: Official pytorch implementation for “Deep Video Inpainting” (CVPR 2019) (github ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/03/03/SSL/" title="Back to Event Basics:Self-Supervised Learning of Image Reconstruction"><img class="post_bg" src="/2023/03/03/SSL/1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Back to Event Basics:Self-Supervised Learning of Image Reconstruction"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/03/03/SSL/" title="Back to Event Basics:Self-Supervised Learning of Image Reconstruction">Back to Event Basics:Self-Supervised Learning of Image Reconstruction</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-03-03T12:29:21.000Z" title="Created 2023-03-03 20:29:21">2023-03-03</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">Back to Event Basics: Self-Supervised Learning of Image Reconstruction for Event Cameras via Photometric Constancy
Abstract：
​	我们的方法是第一个从自监督角度做重构的。我们的方法利用事件相机内部的工作原理，将估计的光流与事件的光度恒常性（photometric constancy）结合来训练网络，不需要ground truth与模拟数据。多个数据集实验表示，提出的自监督方法与sota性能一致。此外，我们提出一种新的轻量级光流估计神经网络，实现高速推理，但在性能上有轻微下降。

分别用contrast maximization proxy loss和photometric constancy进行光流估计与图像重建。
3. Method
​	独立像素的亮度变换信号L(t)L(t)L(t), 单个事件ei=(xi,ti,pi)e_i=(\textbf{x}_i,t_i,p_i)ei​=(xi​,ti​,pi​), 其中xi=(xi,yi)T\textbf{x}_i=( ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2023/03/01/zou-learning/" title="Learning to Reconstruct High Speed and High Dynamic Range Videos from Events"><img class="post_bg" src="/2023/03/01/zou-learning/1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Learning to Reconstruct High Speed and High Dynamic Range Videos from Events"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/03/01/zou-learning/" title="Learning to Reconstruct High Speed and High Dynamic Range Videos from Events">Learning to Reconstruct High Speed and High Dynamic Range Videos from Events</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-03-01T14:13:01.000Z" title="Created 2023-03-01 22:13:01">2023-03-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">Learning to Reconstruct High Speed and High Dynamic Range Videos from Events
Abstract：
​	现有工作遭受unrealistic artifacts，或者不能提供有效的高帧率。本文中，我们提出了一个循环卷积网络重构高速HDR视频，带时序一致性损失。此外，我们还搞了一套原型光学系统，采集高速HDR的真实世界数据集。很快公开，sota？
代码在这：[jackzou233/EventHDR: This is the implementation and dataset for Learning To Reconstruct High Speed and High Dynamic Range Videos From Events, CVPR 2021, by Yunhao Zou, Yinqiang Zheng, Tsuyoshi Takatani and Ying Fu (github.com)](https://github.com/jackzou233/EventHDR)
虽然没有代码
Method:
​ ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2023/03/01/firenet/" title="Fast Image Reconstruction with an Event Camera"><img class="post_bg" src="/2023/03/01/firenet/image-20221229165551063.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Fast Image Reconstruction with an Event Camera"></a></div><div class="recent-post-info"><a class="article-title" href="/2023/03/01/firenet/" title="Fast Image Reconstruction with an Event Camera">Fast Image Reconstruction with an Event Camera</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-03-01T13:42:19.000Z" title="Created 2023-03-01 21:42:19">2023-03-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">Fast Image Reconstruction with an Event Camera
Abstract
​	事件相机是一种功能强大的新型传感器，能够以微秒级的分辨率，无运动模糊的捕捉大动态范围信息。此类相机的优势在于能够检测强度变化信息（事件）而不是直接捕捉强度图像；然后利用算法将事件转化为图像表示，用于分类等应用。
​	之前的工作依赖于hand-crafted空间与时间的平滑技术来从事件中重建图像。最前进的视频重建技术已经通过神经网络实现，神经网络的参数量很大（10M），而且计算成本很高，在现代GPU上，640*480分辨率的一次前向计算需要30ms。我们提出了一种新型的神经网络框架用于从事件重建视频，该框架比最先进的方法更小（38k vs 10M 参数），更快（10ms vs 30ms），且对性能的影响极小。
Method
表征方式：
​	参考E2Vid，用Voxel Grid，B=5.
网络结构：

​	网络结构如上图所示，使用全卷积网络，所有层使用单步长的3×33\times33×3卷积，也就是不下采样。除了最后一层采用1×11\times11×1的卷积。H层16通道卷 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/12/10/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E4%B8%AD%E7%9A%84%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82%EF%BC%88bn%EF%BC%89/" title="图像生成中的归一化（bn）"><img class="post_bg" src="/2022/12/10/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E4%B8%AD%E7%9A%84%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82%EF%BC%88bn%EF%BC%89/cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="图像生成中的归一化（bn）"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/12/10/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E4%B8%AD%E7%9A%84%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82%EF%BC%88bn%EF%BC%89/" title="图像生成中的归一化（bn）">图像生成中的归一化（bn）</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-12-10T02:50:03.000Z" title="Created 2022-12-10 10:50:03">2022-12-10</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/tricks-%E6%80%BB%E7%BB%93/">tricks 总结</a></span></div><div class="content">图像生成中的各种归一化技术
归一化（Normalization）在深度学习中往往指对激活层的输入进行归一化，从而解决一些训练中的问题。
本文主要介绍以下几种归一化技术：

BN - Batch Normalization
LN - Layer Normalization
IN - Instance Normalization
CBN - Conditional Batch Normalization
CIN - Conditional Instance Normalization
AdaIN - Adaptive Instance Normalization
SPADE - Spatial Adaptive Normalization
SEAN - Semantic Region-Adaptive Normalization

BN - Batch Normalization
论文：Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
BN在2015年由S ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/12/09/spade-e2vid/" title="SPADE-E2VID: Spatially-Adaptive Denormalization for Event-Based Video Reconstruction"><img class="post_bg" src="/2022/12/09/spade-e2vid/spade.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SPADE-E2VID: Spatially-Adaptive Denormalization for Event-Based Video Reconstruction"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/12/09/spade-e2vid/" title="SPADE-E2VID: Spatially-Adaptive Denormalization for Event-Based Video Reconstruction">SPADE-E2VID: Spatially-Adaptive Denormalization for Event-Based Video Reconstruction</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-12-09T01:58:03.000Z" title="Created 2022-12-09 09:58:03">2022-12-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">SPADE-E2VID: Spatially-Adaptive Denormalization for Event-Based Video Reconstruction
Abstract
​	与传统的以帧为单位拍摄视频的相机相比，基于事件的相机有许多优点。事件相机具有高时间分辨率，高动态范围，几乎不存在模糊。当在每个像素中报告亮度的变化时，事件传感器产生的数据形成了一个事件链。这一特性使得直接应用现有算法和利用事件摄像机数据变得困难。由于神经网络的发展，基于事件的图像重建取得了重要进展。即使这些神经网络实现了精确的重建，同时保留了事件相机的大部分属性，仍然需要一个初始化时间，重建帧的质量需要尽可能高。在这项工作中，我们提出了SPADE-E2VID神经网络模型，该模型提高了基于事件的重构视频中早期帧的质量，以及整体对比度。SPADE-E2VID模型通过提高第一个重构帧的质量MSE误差为15.87%，SSIM为4.15%，LPIPS为2.5%。此外，我们模型中的SPADE层允许训练我们的模型在没有时间损失函数的情况下重建视频。我们的模型的另一个优点是它有更快的训练时间。在多对一训练模式中， ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/11/18/E2vid-Reducing-the-Sim-to-Real-Gap-for-Event/" title="E2vid+: Reducing the Sim-to-Real Gap for Event"><img class="post_bg" src="/img/hqf.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="E2vid+: Reducing the Sim-to-Real Gap for Event"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/18/E2vid-Reducing-the-Sim-to-Real-Gap-for-Event/" title="E2vid+: Reducing the Sim-to-Real Gap for Event">E2vid+: Reducing the Sim-to-Real Gap for Event</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-11-18T07:44:36.000Z" title="Created 2022-11-18 15:44:36">2022-11-18</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">Reducing the Sim-to Real Gap for Event Cameras
Abstract：
​		事件相机是打破传统范式的新型传感器，它能够以极低的延时记录异步的、逐像素的亮度变化（事件），这使得事件相机成为在高速、大动态范围等传统相机不适用的场景下的最佳选择。最近的工作已经证明基于事件的卷积神经网络在视频重建与光流估计方面取得了较好的效果。我们提出了基于改进训练数据的策略，现有的视频重建SOTA用我们的方法重新训练之后提升了20-40%的性能，而光流网络则高达15%。基于事件的视频重建的一个难点是现有的数据集缺乏大量的ground truth。针对此，我们提出了一个新的数据集High Quality Frames（HQF），其中包含了DAVIS240C拍摄的事件和ground truth，这些图像拥有良好的曝光与极低的运动模糊，我们在HQF和几个现有的主要事件相机数据集上评估了我们的方法。
Contribution：

我们提出了一种生成合成训练集的方法，以现有数据集的统计分析为指导，提高了对真实事件数据的可泛化性。
我们还提出了一种简单的动态训练时间的噪声增强 ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/11/03/E2Vid-High-Speed-and-High-Dynamic-Range-Video-with-an-Event-Camera/" title="E2Vid: High Speed and High Dynamic Range Video with an Event Camera"><img class="post_bg" src="/img/%E6%A1%86%E6%9E%B6.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="E2Vid: High Speed and High Dynamic Range Video with an Event Camera"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/11/03/E2Vid-High-Speed-and-High-Dynamic-Range-Video-with-an-Event-Camera/" title="E2Vid: High Speed and High Dynamic Range Video with an Event Camera">E2Vid: High Speed and High Dynamic Range Video with an Event Camera</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-11-03T13:17:43.000Z" title="Created 2022-11-03 21:17:43">2022-11-03</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">High Speed and High Dynamic Range Video with an Event Camera
​	循环神经网络完成事件相机重构强度图像。
Abstract
​	事件相机是一种新型的传感器，它以异步“事件”流的形式来表示亮度变化，而不是以强度帧的形式。与传统相机相比，它们具有显著的优势：高时间分辨率，高动态范围，无运动模糊。虽然事件流在原则上编码了完整的视觉信号，但从事件流中重建强度图像在实践中是一个不适定问题。现有的重建方法是基于人为制定的先验和对成像过程的强假设以及对自然图像的统计。在这项工作中，我们建议学习从事件流直接从数据重建强度图像，而不是依赖于任何人为制定的先验条件。
​	我们提出了一种新颖的循环网络来从事件流中重建视频，并在大量的模拟事件数据上对其进行训练。在训练期间，我们建议使用感知损失来鼓励重建遵循自然的图像规律。我们进一步扩展了从彩色事件流合成彩色图像的方法。我们的定量实验表明，在图像质量方面，我们的网络超过了最先进的重建方法（&gt;20%），同时能够实时运行。我们证明，该网络能够合成高速现象（如子弹击中物体）的高帧率视频（&gt;500 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/10/30/ET-Net-Event-based-Video-Reconstruction-Using-Transformer/" title="ET-Net: Event-based Video Reconstruction Using Transformer"><img class="post_bg" src="/img/1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ET-Net: Event-based Video Reconstruction Using Transformer"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/10/30/ET-Net-Event-based-Video-Reconstruction-Using-Transformer/" title="ET-Net: Event-based Video Reconstruction Using Transformer">ET-Net: Event-based Video Reconstruction Using Transformer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-10-30T12:33:45.000Z" title="Created 2022-10-30 20:33:45">2022-10-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">Event-based Video Reconstruction Using Transformer
​		利用Transformer对事件相机进行重构。
Abstract：
​		CNN重构取得了不错的效果，但是卷积的内在的局部结构（intrinsic locality）并不支持建模长时间的依赖，而许多视觉任务需要长时间的重构。在我们的论文中，我们提出了一种混合的CNN-Transformer网络来进行基于事件的视频重构，该网络的优势是能够利用CNN的局部信息与Transformer的全局上下文信息。除此之外，我们进一步提出了一个Token Pyramid Aggregation策略，以实现多尺度的token集成，在token空间中关联内部和交叉的语义概念。
Code：https://github.com/WarranWeng/ET-Net
Contribution：

提出了ET-Net，一个新型的CNN-Transformer混合模型
TPA策略，用于多尺度token融合
与CNN对比实验，验证架构有效性

Proposed Method：
​		网络的总体框架如图1所示，图中（ ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/10/29/markdown/" title="markdown"><img class="post_bg" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="markdown"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/10/29/markdown/" title="markdown">markdown</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-10-29T12:35:22.000Z" title="Created 2022-10-29 20:35:22">2022-10-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9D%82%E6%9D%82%E6%8A%80%E6%9C%AF/">杂杂技术</a></span></div><div class="content">Fig 1 Proposed event-based VFI approach.
 
行内公式：$ $
行间公式：$$ $$
上下标：x2−i6x_{2-i}^{6}x2−i6​   x_{2-i}^{6}
适应括号：\left \right
绝对值：\lvert \rvert  两条竖线：\lVert \rVert
定义符号：\triangleq ≜\triangleq≜
尖括号：\langle \rangle
上下取整：\lceil \rceil    \lfloor \rfloor
求和：\sum_{}^{}
I^k\hat{\mathcal{I}}_{k}I^k​
积分：\int_{r=1}^\infty   \iint \iiint
连乘：\prod_{}^{}
圈里一个点，外积：\odot ⊙\odot⊙
箭头：方向+arrow →\rightarrow→ \rightarrow

分式：\frac {}{}  连分式时：\cfrac
根式：\sqrt[4]{\frac xy}
加粗：\textbf{}
属于：\in
乘号：\times  加减号：\pm 除号：\div
点 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2022/11/02/eQmbE4RwJ78Wr2A.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">p4r4mount</div><div class="author-info__description">Event Camera Fresher</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/p4r4mount"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/07/14/utils/" title="Masked and Adaptive Transformer for Exemplar Based Image Translation"><img src="/2023/07/14/utils/image-20230820224628323.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Masked and Adaptive Transformer for Exemplar Based Image Translation"/></a><div class="content"><a class="title" href="/2023/07/14/utils/" title="Masked and Adaptive Transformer for Exemplar Based Image Translation">Masked and Adaptive Transformer for Exemplar Based Image Translation</a><time datetime="2023-07-14T07:08:38.000Z" title="Created 2023-07-14 15:08:38">2023-07-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/06/shuangmu/" title="Learning Event Guided High Dynamic Range Video Reconstruction"><img src="/2023/07/06/shuangmu/image-20230706164138866.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Learning Event Guided High Dynamic Range Video Reconstruction"/></a><div class="content"><a class="title" href="/2023/07/06/shuangmu/" title="Learning Event Guided High Dynamic Range Video Reconstruction">Learning Event Guided High Dynamic Range Video Reconstruction</a><time datetime="2023-07-06T08:23:49.000Z" title="Created 2023-07-06 16:23:49">2023-07-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/06/06/HyperE2vid/" title="HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks"><img src="/2023/06/06/HyperE2vid/image-20230606161530019.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks"/></a><div class="content"><a class="title" href="/2023/06/06/HyperE2vid/" title="HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks">HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks</a><time datetime="2023-06-06T08:02:37.000Z" title="Created 2023-06-06 16:02:37">2023-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/16/evreal/" title="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction"><img src="/2023/05/16/evreal/image-20230516201910502.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction"/></a><div class="content"><a class="title" href="/2023/05/16/evreal/" title="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction">EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction</a><time datetime="2023-05-16T12:08:28.000Z" title="Created 2023-05-16 20:08:28">2023-05-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/24/vrt/" title="VRT:A Video Restoration Transformer"><img src="/2023/04/24/vrt/image-20230424062932595.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="VRT:A Video Restoration Transformer"/></a><div class="content"><a class="title" href="/2023/04/24/vrt/" title="VRT:A Video Restoration Transformer">VRT:A Video Restoration Transformer</a><time datetime="2023-04-23T22:23:44.000Z" title="Created 2023-04-24 06:23:44">2023-04-24</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/paper/"><span class="card-category-list-name">paper</span><span class="card-category-list-count">16</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/tricks-%E6%80%BB%E7%BB%93/"><span class="card-category-list-name">tricks 总结</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9D%82%E6%9D%82%E6%8A%80%E6%9C%AF/"><span class="card-category-list-name">杂杂技术</span><span class="card-category-list-count">2</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/Event-camera/" style="font-size: 1.5em; color: #99a9bf">Event camera</a> <a href="/tags/Image-Generation/" style="font-size: 1.1em; color: #999">Image Generation</a> <a href="/tags/Video-Super-Resolution/" style="font-size: 1.1em; color: #999">Video Super-Resolution</a> <a href="/tags/code/" style="font-size: 1.1em; color: #999">code</a> <a href="/tags/markdown/" style="font-size: 1.1em; color: #999">markdown</a> <a href="/tags/style-transfer/" style="font-size: 1.1em; color: #999">style transfer</a> <a href="/tags/video-generation-inpainting/" style="font-size: 1.1em; color: #999">video generation/inpainting</a> <a href="/tags/video-restoration/" style="font-size: 1.1em; color: #999">video restoration</a> <a href="/tags/video-transfer/" style="font-size: 1.3em; color: #99a1ac">video transfer</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/07/"><span class="card-archive-list-date">July 2023</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/06/"><span class="card-archive-list-date">June 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/05/"><span class="card-archive-list-date">May 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/04/"><span class="card-archive-list-date">April 2023</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/03/"><span class="card-archive-list-date">March 2023</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/12/"><span class="card-archive-list-date">December 2022</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/11/"><span class="card-archive-list-date">November 2022</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/10/"><span class="card-archive-list-date">October 2022</span><span class="card-archive-list-count">3</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">21</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2023-09-03T07:50:07.466Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By p4r4mount</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    window.typed = new Typed("#subtitle", {
      strings: ["RISE FROM THE ASHES"],
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = 'RISE FROM THE ASHES'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>