<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction | Song's blog</title><meta name="author" content="p4r4mount"><meta name="copyright" content="p4r4mount"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="EVREAL: Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction CVPRW 2023  [paper](2305.00434.pdf (arxiv.org)), [code](ercanburak&#x2F;EVREAL: EVREAL: Towards a Comprehen">
<meta property="og:type" content="article">
<meta property="og:title" content="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction">
<meta property="og:url" content="http://example.com/2023/05/16/evreal/index.html">
<meta property="og:site_name" content="Song&#39;s blog">
<meta property="og:description" content="EVREAL: Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction CVPRW 2023  [paper](2305.00434.pdf (arxiv.org)), [code](ercanburak&#x2F;EVREAL: EVREAL: Towards a Comprehen">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2023/05/16/evreal/image-20230516201910502.png">
<meta property="article:published_time" content="2023-05-16T12:08:28.000Z">
<meta property="article:modified_time" content="2023-07-02T02:22:48.436Z">
<meta property="article:author" content="p4r4mount">
<meta property="article:tag" content="Event camera">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/05/16/evreal/image-20230516201910502.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2023/05/16/evreal/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-07-02 10:22:48'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /><link rel="alternate" href="/atom.xml" title="Song's blog" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://s2.loli.net/2022/11/02/eQmbE4RwJ78Wr2A.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/2023/05/16/evreal/image-20230516201910502.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Song's blog</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-05-16T12:08:28.000Z" title="Created 2023-05-16 20:08:28">2023-05-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-07-02T02:22:48.436Z" title="Updated 2023-07-02 10:22:48">2023-07-02</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/paper/">paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>EVREAL: Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction</h1>
<p>CVPRW 2023  [paper](<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2305.00434.pdf">2305.00434.pdf (arxiv.org)</a>), [code](<a target="_blank" rel="noopener" href="https://github.com/ercanburak/EVREAL">ercanburak/EVREAL: EVREAL: Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction (CVPRW 2023) (github.com)</a>)</p>
<h2 id="abstract">Abstract:</h2>
<p>​	事件流对human来说不太好理解，因此需要intensity重构，最近的一些深度学习工作体现出了重构的意义，但这个问题并没有被完全解决。为了更好的对比不同方法，标准化evaluation protocols与不同的测试集是有必要的。我们提出了一种统一的评估方法，并介绍了一个名为<strong>EVREAL</strong>的开源框架，对提出的各种基于事件的视频重建方法进行了全面的benchmark测试与分析。基于此，我们对sota方法进行了详细分析，并对这些方法在不同设置，具有挑战性的场景和下游任务的性能提供了有价值的见解。</p>
<h2 id="introduction">Introduction:</h2>
<p>​	由于缺乏标准的评估程序，很难公平地比较不同方法的性能。评估程序的细节有时没有明确定义，即使每个小细节都可能显著地改变结果，这激发了对开放源代码和用于评估的标准化协议的需求。除了定理标准化协议以外，还需要一个大的真实数据集，涵盖现实生活中的各种情况，如ImageNet和MSCOCO等，基于事件的视觉是较新的领域，没有这样的数据集，局限于特定的场景与领域。</p>
<p>​	事件数据的优势是在光照不足或快速运动的地方有效成像，因此需要在这些条件下进行评估。然而dv在这些场合很垃圾，因此没法有监督量化。正常情况下用LPIPS，PSNR和SSIM，而且LPIPS作为一个full-reference metric，在distortions上训的，而这在事件重构数据中不常见。</p>
<p>​	重建是复杂的任务，有许多变量，包含传感器噪声，参数，事件产生率等等，现有方法没有探究在这些参数上的robustness。事件相机的一个优势是低延时和非冗余数据流，因此为了实时，计算效率与视觉质量同样重要，因此模型太大也不合适。</p>
<p>​	我们提出EVREAL，基于事件的视频重建评估分析库，提供了统一的evaluation pipeline对预训练的nn进行测试并提供结果分析工具来可视化及比较重建分数。我们用大量真实世界的测试序列，各种全参考和无参考的图像质量指标，在快速，低光照，高动态范围等具有挑战性的场景进行定量与定性分析，并验证不同设置的鲁棒性。还整了些下游任务。</p>
<p>​	几个贡献：</p>
<ul>
<li>统一评估方法与开源框架</li>
<li>快速、低光照、大动态等挑战性测试集</li>
<li>在不同设置下的鲁棒性，如事件率，常量稀疏度等</li>
<li>下游任务</li>
</ul>
<h2 id="methodology-of-evaluation-and-analysis">Methodology of Evaluation and Analysis</h2>
<h3 id="2-1-task-description：">2.1.  Task Description：</h3>
<p>​	重建任务，没啥好说。</p>
<h3 id="2-2-evaluation-framework-and-pipeline：">2.2. Evaluation Framework and Pipeline：</h3>
<p>​	EVREAL实现了几个标准化组件，如下图，包含事件预处理、事件分组、事件表示、表示处理和图像后处理。包含了评估重构视频中每帧视觉质量的组件，分为全参考指标和无参考指标。前者用于优质gt，后者用于trash gt。EVREAL还包含一个分析工具。给定几种方法生成的一组rec，收集gt frame，事件可视化，事件率统计数据和度量的瞬时值。随后生成一个输出视频，时间同步显示，包括定量指标。</p>
<p>​	我们的方法受限场景以及失败案例有特别价值，例如，由于方法的顺序性，能够揭示噪声重建对于未来重建的影响。这些场景能够从定量度量图中直观识别。</p>
<p><img src="image-20230516201910502.png" alt="image-20230516201910502"></p>
<p><strong>Event pre-processing.</strong> 事件预处理，包括时序下采样和添加人工事件噪声，增强鲁棒性。</p>
<p><strong>Event grouping.</strong> 孤立事件有限，因此处理为整体，有几个方法：</p>
<ul>
<li><strong>Fixed-number:</strong> 每<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>G</mi></msub></mrow><annotation encoding="application/x-tex">N_G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>个事件分一组，组的形成速率根据传入事件速率变化。</li>
<li><strong>Fixed-duration:</strong> 每<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mi>G</mi></msub></mrow><annotation encoding="application/x-tex">T_G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">G</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>时间间隔分一组，每个组的事件数根据传入事件速率变化。</li>
<li><strong>Between-frames:</strong> 有gt帧的话，可以将连续帧间的每个事件归为一组。基础帧以固定速率到达，该情况其实是按时间间隔分的特殊情况。不过连续帧间的时间差可能并不固定，因为真实数据集中相机曝光时间不同。</li>
</ul>
<p><strong>Event representation.</strong> 为了利用CNN架构处理事件，常用方法是放进网格，如voxel grid。</p>
<p><strong>Representation pre-processing.</strong> 形成表征后，对事件进行预处理，如裁剪或归一化，本文不提。</p>
<p><strong>Neural network inference.</strong> pytorch</p>
<p><strong>Post-processing.</strong> 后处理，如spade做的robust最大最小归一化，本文不后处理。</p>
<h3 id="2-3-tested-approaches：">2.3. Tested Approaches：</h3>
<p>​	我们比较了文献中的七种方法，基于PyTorch的开源模型代码和预训练模型。这些方法包括E2VID[21]、FireNet[23]、FireNet+和E2VID+[24]、SPADE-E2VID[2]、SSL-E2VID[18]和ET-Net[30]。需要注意的是，E2VID+和SSL-E2VID的深层网络架构与E2VID相同，FireNet+的深层网络架构与FireNet相同。</p>
<p>​	在这里，我们利用作者公开分享的预训练模型，并在相同的数据集上在通用的实验评估设置下对它们进行评估。</p>
<h3 id="2-4-quantitative-image-quality-metrics：">2.4. Quantitative Image Quality Metrics：</h3>
<p>​	为了评估，用全参考的和无参考的指标，全参考需要gt，无参考不需要gt，直接给重构图像就行。全参考用：MSE，SSIM，LPIPS；无参考用：BRISQUE，NIQE和MANIQA。dv没法用时用这些度量。BRISQUE和 NIQE是传统度量，采用hand-crafted特征，计算与自然场景统计特征的一致性，考虑各种合成的和真实的distortions，如模糊，噪声和压缩等。另一方面，MANIQA时基于深度学习的方法，采用transformer架构，端到端训练，以评估感知图像质量，同时特别关注nn输出中的distortion。不做直方图均衡！！！</p>
<h3 id="2-5-datasets：">2.5. Datasets：</h3>
<p>​	采用三个常用的数据集，ECD（也就是IJRR），MVSEC和HQF。此外，我们使用BS-ERGB（Beam Splitter Event and RGB）中的handled序列。用全参考指标来评估模型性能。在一些挑战性场景中使用无参考指标，包括快速运动、低光照和大动态范围场景。</p>
<p>​	具体来说，使用ECD的后部分，摄像机的快速运动（ECD-FAST），MVSEC的夜间驾驶序列（MVSEC-NIGHT），以及来自e2vid中的的HDR序列。</p>
<h3 id="2-6-robustness-analysis：">2.6. Robustness Analysis：</h3>
<p>​	为了分析影响时间重建性能的因素，考虑几个变量：event rate，event tensor sparsity，image reconstruction rate，temporal irregularity四个因素。利用LPIPS在数据集常用序列中验证。</p>
<p>​	<strong>Event rate.</strong> 为评估事件率的鲁棒性，采用帧间事件分组（between-frame），并收集事件率的统计数据，以每秒事件数为单位。用网络重建并计算每个时间步长的LPIPS。我们将event rate spectrum划分为十个等间隔的bin，并计算不同方法每个bin的LPIPS。以此评估方法在不同事件率下的性能，确定对事件率的鲁棒性。</p>
<p>​	<strong>Tensor sparsity.</strong> 事件张量的稀疏性，使用固定数量分组（fixed-number），和1ms的tolerance（容差）进行实验。将gt与rec相匹配，该方法中每组的事件数量相同，产生具有相同稀疏度的事件张量。进行9次不同实验，事件数从5k到45k，然后算平均LPIPS。</p>
<p>​	如果场景中存在慢动作或少量纹理，固定事件数分组会导致跨越较长的时间。此外，事件相机的运动和纹理可能集中在小区域中，不会均匀分布，这种情况下，在表征中的时间离散化会压缩更多时间信息。容易导致模糊等伪影。</p>
<p>​	<strong>Reconstruction rate.</strong> 帧重建率对方法性能的影响，使用固定时间间隔（fixed-duration）分组，每秒生成固定数量的帧，进行10次实验，每次实验分组持续时间从10ms到100ms，帧重建速率从10FPS到100FPS。使用1ms容差来匹配帧。计算LPIPS，看不同帧速率下的性能。</p>
<p>​	<strong>Temporal irregularity.</strong> 评估不规则时间间隔生成帧时的鲁棒性，从每个序列中除去一定百分比的基础gt帧并使用帧间间隔（between-frame）的事件分组，进行10次实验，丢弃率从0.0到0.9不等，计算LPIPS。</p>
<h3 id="2-7-analysis-on-downstream-tasks：">2.7. Analysis on Downstream Tasks：</h3>
<p>​	目标检测，图像分类，相机标定三个下游任务。</p>
<h2 id="3-evaluation-results-and-discussion">3. Evaluation Results and Discussion</h2>
<p>​	下表给出了四个数据集上重建的定量结果，用的时全参考指标MSL。ET-Net和E2VID+是最好的。自监督的ssl居然在ECD和MVSEC有最好的MSE，我只能说这个指标不太行。</p>
<p><img src="image-20230518175507669.png" alt="image-20230518175507669"></p>
<p>​	下图为定性结果。ECD和MVSEC的曝光不足，SSL的重建非常暗，MSE垃圾指标。</p>
<p><img src="image-20230518175558439.png" alt="image-20230518175558439"></p>
<p>​	下表是无参考指标BRISQUE，NIQE和MANIQA第快速运动、低光照和高动态范围的挑战性场景进行的定量分析，居然是E2VID和FireNet+最好，SPADE和SSL最低。有趣的是，标准数据集上分数最高的ET-Net在这些数据集上不够好。说明标准数据集不足以衡量模型真正的性能。</p>
<p><img src="image-20230518175618755.png" alt="image-20230518175618755"></p>
<p>​	下表是下游任务上的定量结果，E2VID在检测和分类上最好，FireNet二三名，spade前俩垃圾，标定最好。有趣的是，相机标定重构后比gt要好？逆天。</p>
<p><img src="image-20230519143621002.png" alt="image-20230519143621002"></p>
<p>​	下图是鲁棒性分析的LPIPS表格，a表示事件重建率，ET-Net和E2VID+非常稳定，其他方法只在某些地方好。b表示张量稀疏度，组内事件数增加时，spade就变垃圾了，其他的还好。c是时间不规则性，当丢掉10%gt时，所有方法都有提升，说明原始事件分组不是最优的。事件率增加时，spade变垃圾，其他都变好。</p>
<p><img src="image-20230519144600179.png" alt="image-20230519144600179"></p>
<h2 id="4-验证集划分">4.验证集划分</h2>
<table>
<thead>
<tr>
<th style="text-align:center">ECD/IJRR</th>
<th style="text-align:center">normal</th>
<th style="text-align:center">fast</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">boxes_6dof</td>
<td style="text-align:center">109-434</td>
<td style="text-align:center">435-1296</td>
</tr>
<tr>
<td style="text-align:center">dynamic_6dof</td>
<td style="text-align:center">107-424</td>
<td style="text-align:center">425-1267</td>
</tr>
<tr>
<td style="text-align:center">poster_6dof</td>
<td style="text-align:center">114-453</td>
<td style="text-align:center">454-1356</td>
</tr>
<tr>
<td style="text-align:center">shapes_6dof</td>
<td style="text-align:center">114-453</td>
<td style="text-align:center">454-1354</td>
</tr>
<tr>
<td style="text-align:center">calibration</td>
<td style="text-align:center">119-475</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">office_zigzag</td>
<td style="text-align:center">114-246</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">slider_depth</td>
<td style="text-align:center">26-64</td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">MVSEC</th>
<th style="text-align:center">normal</th>
<th style="text-align:center">night</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">indoor_flying1234_data</td>
<td style="text-align:center"></td>
<td style="text-align:center">outdoor_night1_data</td>
</tr>
<tr>
<td style="text-align:center">outdoor_day12_data</td>
<td style="text-align:center"></td>
<td style="text-align:center">outdoor_night2_data</td>
</tr>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">outdoor_night3_data</td>
</tr>
</tbody>
</table>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://example.com">p4r4mount</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2023/05/16/evreal/">http://example.com/2023/05/16/evreal/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Event-camera/">Event camera</a></div><div class="post_share"><div class="social-share" data-image="/2023/05/16/evreal/image-20230516201910502.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/06/06/HyperE2vid/"><img class="prev-cover" src="/2023/06/06/HyperE2vid/image-20230606161530019.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks</div></div></a></div><div class="next-post pull-right"><a href="/2023/04/24/vrt/"><img class="next-cover" src="/2023/04/24/vrt/image-20230424062932595.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">VRT:A Video Restoration Transformer</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2022/11/03/E2Vid-High-Speed-and-High-Dynamic-Range-Video-with-an-Event-Camera/" title="E2Vid: High Speed and High Dynamic Range Video with an Event Camera"><img class="cover" src="/img/%E6%A1%86%E6%9E%B6.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-03</div><div class="title">E2Vid: High Speed and High Dynamic Range Video with an Event Camera</div></div></a></div><div><a href="/2022/12/09/spade-e2vid/" title="SPADE-E2VID: Spatially-Adaptive Denormalization for Event-Based Video Reconstruction"><img class="cover" src="/2022/12/09/spade-e2vid/spade.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-09</div><div class="title">SPADE-E2VID: Spatially-Adaptive Denormalization for Event-Based Video Reconstruction</div></div></a></div><div><a href="/2022/11/18/E2vid-Reducing-the-Sim-to-Real-Gap-for-Event/" title="E2vid+: Reducing the Sim-to-Real Gap for Event"><img class="cover" src="/img/hqf.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-18</div><div class="title">E2vid+: Reducing the Sim-to-Real Gap for Event</div></div></a></div><div><a href="/2022/10/30/ET-Net-Event-based-Video-Reconstruction-Using-Transformer/" title="ET-Net: Event-based Video Reconstruction Using Transformer"><img class="cover" src="/img/1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-30</div><div class="title">ET-Net: Event-based Video Reconstruction Using Transformer</div></div></a></div><div><a href="/2023/03/01/firenet/" title="Fast Image Reconstruction with an Event Camera"><img class="cover" src="/2023/03/01/firenet/image-20221229165551063.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-01</div><div class="title">Fast Image Reconstruction with an Event Camera</div></div></a></div><div><a href="/2023/03/01/zou-learning/" title="Learning to Reconstruct High Speed and High Dynamic Range Videos from Events"><img class="cover" src="/2023/03/01/zou-learning/1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-01</div><div class="title">Learning to Reconstruct High Speed and High Dynamic Range Videos from Events</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://s2.loli.net/2022/11/02/eQmbE4RwJ78Wr2A.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">p4r4mount</div><div class="author-info__description">Event Camera Fresher</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">20</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/p4r4mount"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">EVREAL: Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#abstract"><span class="toc-number">1.1.</span> <span class="toc-text">Abstract:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#introduction"><span class="toc-number">1.2.</span> <span class="toc-text">Introduction:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#methodology-of-evaluation-and-analysis"><span class="toc-number">1.3.</span> <span class="toc-text">Methodology of Evaluation and Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-task-description%EF%BC%9A"><span class="toc-number">1.3.1.</span> <span class="toc-text">2.1.  Task Description：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-evaluation-framework-and-pipeline%EF%BC%9A"><span class="toc-number">1.3.2.</span> <span class="toc-text">2.2. Evaluation Framework and Pipeline：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-tested-approaches%EF%BC%9A"><span class="toc-number">1.3.3.</span> <span class="toc-text">2.3. Tested Approaches：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-quantitative-image-quality-metrics%EF%BC%9A"><span class="toc-number">1.3.4.</span> <span class="toc-text">2.4. Quantitative Image Quality Metrics：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-datasets%EF%BC%9A"><span class="toc-number">1.3.5.</span> <span class="toc-text">2.5. Datasets：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-6-robustness-analysis%EF%BC%9A"><span class="toc-number">1.3.6.</span> <span class="toc-text">2.6. Robustness Analysis：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-7-analysis-on-downstream-tasks%EF%BC%9A"><span class="toc-number">1.3.7.</span> <span class="toc-text">2.7. Analysis on Downstream Tasks：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-evaluation-results-and-discussion"><span class="toc-number">1.4.</span> <span class="toc-text">3. Evaluation Results and Discussion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E9%AA%8C%E8%AF%81%E9%9B%86%E5%88%92%E5%88%86"><span class="toc-number">1.5.</span> <span class="toc-text">4.验证集划分</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/07/06/shuangmu/" title="Learning Event Guided High Dynamic Range Video Reconstruction"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Learning Event Guided High Dynamic Range Video Reconstruction"/></a><div class="content"><a class="title" href="/2023/07/06/shuangmu/" title="Learning Event Guided High Dynamic Range Video Reconstruction">Learning Event Guided High Dynamic Range Video Reconstruction</a><time datetime="2023-07-06T08:23:49.000Z" title="Created 2023-07-06 16:23:49">2023-07-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/06/06/HyperE2vid/" title="HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks"><img src="/2023/06/06/HyperE2vid/image-20230606161530019.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks"/></a><div class="content"><a class="title" href="/2023/06/06/HyperE2vid/" title="HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks">HyperE2VID:Improving Event-Based Video Reconstruction via Hypernetworks</a><time datetime="2023-06-06T08:02:37.000Z" title="Created 2023-06-06 16:02:37">2023-06-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/16/evreal/" title="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction"><img src="/2023/05/16/evreal/image-20230516201910502.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction"/></a><div class="content"><a class="title" href="/2023/05/16/evreal/" title="EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction">EVREAL:Towards a Comprehensive Benchmark and Analysis Suite for Event-based Video Reconstruction</a><time datetime="2023-05-16T12:08:28.000Z" title="Created 2023-05-16 20:08:28">2023-05-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/24/vrt/" title="VRT:A Video Restoration Transformer"><img src="/2023/04/24/vrt/image-20230424062932595.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="VRT:A Video Restoration Transformer"/></a><div class="content"><a class="title" href="/2023/04/24/vrt/" title="VRT:A Video Restoration Transformer">VRT:A Video Restoration Transformer</a><time datetime="2023-04-23T22:23:44.000Z" title="Created 2023-04-24 06:23:44">2023-04-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/13/local-global-SR/" title="Local-Global Temporal Difference Learning for Satellite Video Super-Resolution"><img src="/2023/04/13/local-global-SR/image-20230413070915148.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Local-Global Temporal Difference Learning for Satellite Video Super-Resolution"/></a><div class="content"><a class="title" href="/2023/04/13/local-global-SR/" title="Local-Global Temporal Difference Learning for Satellite Video Super-Resolution">Local-Global Temporal Difference Learning for Satellite Video Super-Resolution</a><time datetime="2023-04-12T23:00:53.000Z" title="Created 2023-04-13 07:00:53">2023-04-13</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By p4r4mount</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>